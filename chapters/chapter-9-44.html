<p>Apache Kafka is an event streaming middleware based on distributed logs. While that may sound complicated at first sight, all you really need to understand is that Kafka offers streams of event records, where producers can append new records, and consumers can walk back and forth along streams. For instance incoming pedometer step updates form a stream where each event is an update sent by a device, and the ingestion service produces these events. On the other hand various consumers can look at the events on that stream, be it to populate databases, compute statistics, etc. Events remain in a stream for some amount of time, or until the stream is too big and has to discard its oldest records.</p>