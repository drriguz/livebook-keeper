<p>It is safe to conclude that the tested service implementations deliver solid performance under load. You could try to increase the number of workers for Hey and see what happens with bigger workloads (see the <code class="code">-c</code> flag of the <code class="code">hey</code> tool). You could also perform latency measures with increasing request rates (see the <code class="code">-q</code> flag), but note that by default Hey does not do rate limiting, so in the previous runs Hey did the best it could with 50 workers (the default).</p>